# ğŸ’¬ Twitter Sentiment Analysis (BiLSTM + GloVe + Streamlit)

> Analyze emotions behind tweets using **Deep Learning and NLP**.  
This project performs **Twitter Sentiment Analysis** using a **Bidirectional LSTM (BiLSTM)** model with **GloVe word embeddings**, deployed as an interactive **Streamlit web app**.

---

## ğŸš€ Overview

This project classifies tweets into **Positive**, **Negative**, or **Neutral** sentiments using a deep learning model trained on a labeled Twitter dataset.

- ğŸ”  **Preprocessing:** Cleans and tokenizes tweets  
- ğŸ§  **Model:** BiLSTM with pretrained **GloVe (100d)** embeddings  
- âš–ï¸ **Balanced Training:** Uses `class_weight` to handle imbalance  
- ğŸŒ **Deployment:** Interactive Streamlit interface for live predictions  
- ğŸ“Š **Accuracy:** ~85% on test data  

---

## ğŸ§© Project Structure

```bash
ğŸ“ Twitter-Sentiment-Analysis
â”‚
â”œâ”€â”€ app.py                          # Streamlit web app
â”œâ”€â”€ twitter.ipynb                   # Model training notebook
â”œâ”€â”€ sentiment_bilstm_glov.h5        # Trained BiLSTM model
â”œâ”€â”€ sentiment_tokenizer_glov.joblib # Tokenizer for preprocessing
â”œâ”€â”€ Twitter_Data.csv                # Dataset
â”œâ”€â”€ glove.6B.100d.txt               # GloVe embeddings (100d)
â””â”€â”€ README.md                       # Documentation

---

## ğŸ§  Key Insights
Training is handled in twitter.ipynb and includes:
- Text cleaning and tokenization
- Label encoding (positive, neutral, negative)
- Loading GloVe 100d embeddings
- Building and training a BiLSTM model
- Evaluating performance and saving model/tokenizer

---

## ğŸ§® Model Architecture

Embedding (GloVe 100d)
â†“
Bidirectional LSTM (128 units)
â†“
Dropout (0.5)
â†“
Dense (64, ReLU)
â†“
Dense (3, Softmax)

---

### ğŸ“Š Model Summary

| Layer (Type) | Output Shape | Param # |
|---------------|---------------|----------|
| Embedding (Non-trainable GloVe) | (None, 50, 100) | 2,000,000+ |
| Bidirectional LSTM (128 units) | (None, 256) | 234,496 |
| Dropout (0.5) | (None, 256) | 0 |
| Dense (64, ReLU) | (None, 64) | 16,448 |
| Dense (Softmax) | (None, 3) | 195 |
| **Total Parameters** | **~2.25 Million** |  |

---

## ğŸ§¾ Model Training

Model training is handled inside **`twitter.ipynb`** and follows these main steps:

1. Clean and preprocess the dataset  
2. Tokenize and pad tweet sequences  
3. Encode sentiment labels  
4. Load pretrained **GloVe (100d)** embeddings  
5. Build and train the **BiLSTM** model  
6. Use `class_weight` to manage class imbalance  
7. Evaluate and save both the model and tokenizer  

### ğŸ’¾ Saved Files

| File Name | Description |
|------------|-------------|
| `sentiment_bilstm_glov.h5` | Trained BiLSTM model |
| `sentiment_tokenizer_glov.joblib` | Tokenizer used for preprocessing |

---

## ğŸ§ª Model Evaluation

| Metric | Score |
|--------|--------|
| **Accuracy** | 84â€“86% |
| **Loss** | ~0.40 |
| **Optimizer** | Adam |
| **Loss Function** | Categorical Crossentropy |

**Visualizations:**
- Confusion Matrix  
- Accuracy vs. Loss Curves  
*(Available in the Jupyter notebook)*

---

## ğŸ’» Running the Streamlit App

Run the app locally using the command below:

```bash
streamlit run app.py


âœ… **How to use it:**
1. Copy everything above (including the Markdown formatting).
2. Paste it directly into your `README.md` file.
3. Replace `<your-username>` with your actual GitHub username.
4. (Optional) Add a screenshot of your Streamlit app below the **Example Predictions** section for visual impact.

Would you like me to also give you a **short GitHub description** (the one that appears below your repo title, e.g. â€œAI-powered Twitter Sentiment Classifier using BiLSTM + Streamlitâ€)? It helps attract views.






